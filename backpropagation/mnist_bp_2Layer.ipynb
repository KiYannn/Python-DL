{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 The XMU Authors. All Rights Reserved.\n",
    "邱明、曾捷航、林金鹏、景丽婷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#如果要在Python 2.7的代码中直接使用Python 3.x的语法，可以通过__future__引入对应的模块\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "\n",
    "#是只引入tensorflow.examples.tutorials.mnist包里的input_data类\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#给tensorflow包一个别称tf\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sigmod的导函数  \n",
    "$ \\sigma^\\prime (x) = sigmoid(x)(1-sigmoid(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmaprime(x):\n",
    "    return tf.multiply(tf.sigmoid(x),tf.subtract(tf.constant(1.0),tf.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对一个Tensor进行多种数据汇总\n",
    "计算平均值，标准差，最大值和最小值，以及输出柱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    with tf.name_scope('summary_'+name):\n",
    "        mean=tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)  #输出平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev=tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev) #输出标准差\n",
    "        tf.summary.scalar('max',tf.reduce_max(var)) #输出最大值\n",
    "        tf.summary.scalar('min',tf.reduce_min(var)) #输出最小值\n",
    "        tf.summary.histogram('histogram',var) #输出柱状图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义神经网络的结构相关参数\n",
    "ETA = 0.01   #学习率\n",
    "EPOCHS = 2000  #训练次数\n",
    "BATCH_SIZE = 1000    #批量数\n",
    "TEST_EPOCHS = 10  #测试间隔\n",
    "\n",
    "INPUT_NODE = 784 #输入节点数\n",
    "OUTPUT_NODE = 10    #输出的节点数\n",
    "\n",
    "#通过改变下面这个参数来改变中间神经元的个数\n",
    "HIDDENLAYER_NODE = 30    #隐藏层的节点数\n",
    "LOG_PATH='log/mnist_bp_2Layer/'  #图输出的目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从网络上下载数据, 导入程序，放在mnist变量中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name=\"x-input\"是给变量起个名字，便于以后用名字表示这个placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 输入的图片\n",
    "x = tf.placeholder(tf.float32, [None, INPUT_NODE], name=\"x-input\")\n",
    "# 输入图片的标签\n",
    "y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name=\"y-input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# z与权重W和偏置项b的关系   \n",
    "$$ z_k^{l+1}=\\sum_{j} W_{kj}^{l+1}x_j^l+b_k^{l+1} $$\n",
    "\n",
    "# 激活函数   \n",
    "$$sigmoid(z) = \\frac{1}{1+e^{-z}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#第一层\n",
    "W_1 = tf.Variable(tf.zeros([INPUT_NODE, HIDDENLAYER_NODE]))\n",
    "b_1 = tf.Variable(tf.zeros(HIDDENLAYER_NODE))\n",
    "z_1 = tf.matmul(x, W_1) + b_1\n",
    "y_1 = tf.sigmoid(z_1)\n",
    "    \n",
    "\n",
    "#第二层\n",
    "W_2 = tf.Variable(tf.zeros([HIDDENLAYER_NODE, OUTPUT_NODE]))\n",
    "b_2 = tf.Variable(tf.zeros(OUTPUT_NODE))\n",
    "z_2 = tf.matmul(y_1, W_2) + b_2\n",
    "y_2 = tf.sigmoid(z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数\n",
    "$$C = \\frac{1}{2}(y_2 - y\\_)^2$$\n",
    "$$\\frac{\\partial C} {\\partial z} = (y_2 - y\\_) \\sigma^\\prime(z)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadratic_cost = tf.subtract(y_2,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播 \n",
    "## 第二层的修改值\n",
    "$$\\delta_j^2 = \\frac{\\partial C}{\\partial y_j^1}\\sigma^\\prime (z_j^2) $$     \n",
    "$$\\frac{\\partial C}{\\partial W_{kj}^2} = y_k^1\\delta_j^2 $$\n",
    "$$\\frac{\\partial C}{\\partial b_j^2} = \\delta_j^2$$\n",
    "$$W^2 = W^2 - \\eta\\frac{\\partial C}{\\partial z^2} y^1$$\n",
    "$$b^2 = b^2 - \\eta\\frac{\\partial C}{\\partial z^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_z2 = tf.multiply(quadratic_cost, sigmaprime(z_2))\n",
    "d_b2 = d_z2\n",
    "d_w2 = tf.matmul(tf.transpose(y_1),d_z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一层的修改值\n",
    "$$\\delta_j^1 = \\sum_k{W_{kj}^2\\delta_k^2\\sigma^\\prime (z_j^1)} $$     \n",
    "$$\\frac{\\partial C}{\\partial W_{kj}^1} = x\\delta_j^1 $$\n",
    "$$\\frac{\\partial C}{\\partial b_j^1} = \\delta_j^1$$\n",
    "$$W^1 = W^1 - {\\eta}x\\delta_j^1$$\n",
    "$$b^2 = b^2 - \\eta\\delta_j^1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_z1 = tf.multiply(tf.matmul(d_z2,tf.transpose(W_2)), sigmaprime(z_1))\n",
    "d_b1 = d_z1\n",
    "d_w1 = tf.matmul(tf.transpose(x),d_z1)\n",
    "    \n",
    "step = [\n",
    "    tf.assign(W_1,\n",
    "            tf.subtract(W_1, tf.multiply(ETA, d_w1)))\n",
    "  , tf.assign(b_1,\n",
    "            tf.subtract(b_1, tf.multiply(ETA,\n",
    "                               tf.reduce_mean(d_b1, axis=[0]))))\n",
    "  , tf.assign(W_2,\n",
    "            tf.subtract(W_2, tf.multiply(ETA, d_w2)))\n",
    "  , tf.assign(b_2,\n",
    "            tf.subtract(b_2, tf.multiply(ETA,\n",
    "                               tf.reduce_mean(d_b2, axis=[0]))))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用测试数据集检验模型的正确率\n",
    "## tf.argmax返回第一维最大值的索引,由于数据格式为类似[0,1,0,0,0,0,0,0,0,0],所以索引即为识别出的阿拉伯数字\n",
    "## tf.equal判断张量中对应下表的值是否相等,相等返回true,不相等返回false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_mat = tf.equal(tf.argmax(y_2,1),tf.argmax(y_,1))\n",
    "accuracy_result = tf.reduce_mean(tf.cast(accuracy_mat,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Summary把数据写入事件文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一层\n",
    "with tf.name_scope('layer1'):\n",
    "    variable_summaries(W_1,'W_1')\n",
    "    variable_summaries(b_1,'b_1')\n",
    "    \n",
    "#第二层\n",
    "with tf.name_scope('layer2'):\n",
    "    variable_summaries(W_2,'W_2')\n",
    "    variable_summaries(b_2,'b_2')\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    tf.summary.scalar('accuracy_rate',accuracy_result)\n",
    "    \n",
    "#把所有的summary合到一张图上\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "#设置训练和测试的Writer\n",
    "train_writer = tf.summary.FileWriter(LOG_PATH+'/train_'+str(HIDDENLAYER_NODE)+'_'+str(BATCH_SIZE)+'_'+str(EPOCHS)+'_'+str(ETA),graph=tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(LOG_PATH+'/test_'+str(HIDDENLAYER_NODE)+'_'+str(BATCH_SIZE)+'_'+str(EPOCHS)+'_'+str(ETA),graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化之前定义好的全部变量\n",
    "    tf.global_variables_initializer().run()\n",
    "  \n",
    "    #对模型训练EPOCHS次\n",
    "    #随机选取BATCH_SIZE个图像数据进行训练\n",
    "    for i in range(EPOCHS):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "        summary,_=sess.run([merged,step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        # 把Summary加入到训练数据的Writer中\n",
    "        train_writer.add_summary(summary,i)\n",
    "        if i % TEST_EPOCHS == 0 :\n",
    "            summary = sess.run(merged,feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            test_writer.add_summary(summary,i)\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
